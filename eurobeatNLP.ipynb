{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8daf4d7-c9a9-4325-bc9d-60b5028ed40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63b501b7-14a7-4aa4-adbc-40cd12e3d651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants\n",
    "SEQUENCE_LEN = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8834c22a-6ac0-4f20-8c42-9473761a499b",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "- die dictionaries sollen funktional, unabha√§ngig vond er klasse sein, also werden die songs als solche ebreits auserhalb genereirt, dann einfach songs drausen generieren, dict anlegen, dann klasse schreiben die songs bekommt\n",
    "\n",
    "- https://github.com/LeanManager/NLP-PyTorch/blob/master/Character-Level%20LSTM%20with%20PyTorch.ipynb\n",
    "- https://www.analyticsvidhya.com/blog/2020/08/build-a-natural-language-generation-nlg-system-using-pytorch/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fc8bd7-7936-413c-928d-a1bcd2e430d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load and prepare Data\n",
    "\n",
    "Lets begin by importing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ab4ea04-779b-43f1-9c68-bf8ab7821eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'eurobeat_lyrics.csv'\n",
    "\n",
    "songs  = np.array(open(file,'r').read().split(';'))\n",
    "songs = songs[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7bfda95-d96c-4036-a21c-20ebc9ec040d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to call in dataset class\n",
    "def getSongs(filepath):\n",
    "    songs  = np.array(open(file,'r').read().split(';'))\n",
    "    return songs[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae378ca-d926-4a6a-b529-e5bca65c542b",
   "metadata": {},
   "source": [
    "The songs have different lengths. We want to split the songs in sequences of characters, all the same length. We also want the sequences to overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e67ac6f-7490-4d86-b048-999c6139b760",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a whole song and return an array (n, seq_len) of n seqeunces of length seq_len, which are the characters of the song\n",
    "#each sequence has teh same length\n",
    "def song2sequences(song, seq_len):\n",
    "    song_len = len(song)\n",
    "    n_seq = 2*(song_len//seq_len)\n",
    "    seq = np.empty((n_seq, seq_len), dtype=str)\n",
    "    \n",
    "    song = np.array([ch for ch in song])\n",
    "    for i in range(n_seq-1):\n",
    "        seq[i] = song[int(i*(seq_len/2)) : int(seq_len + i*seq_len/2)]\n",
    "    seq[n_seq-1] = song[-(seq_len):]\n",
    "    \n",
    "    return seq\n",
    "\n",
    "#lets create all the sequences for all our songs and concatenate them in one array\n",
    "#so proud i wrote this line myself\n",
    "def songs2sequences(songs, seq_len=SEQUENCE_LEN):\n",
    "    return np.concatenate(([song2sequences(song, seq_len) for song in songs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b9afada-c18b-4cc1-9ea0-99ec55abfa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def songs2contSequences(allsongs, seq_len):\n",
    "    #1. turn all songs into 1 string\n",
    "    together = '\\n\\n'.join(allsongs)\n",
    "    chars = [char for char in together]\n",
    "    n_seq = len(together)//seq_len\n",
    "\n",
    "    sequences = []\n",
    "    for i in range(n_seq):\n",
    "        sequences.append(chars[i*seq_len:(i+1)*seq_len])\n",
    "\n",
    "    return np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a93e7933-8e2c-46fa-b089-7836df31fb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequences = songs2sequences(songs,SEQUENCE_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f66af8-381a-444c-915f-d08c97906550",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "Create a dictionary to link letters to numbers.\n",
    "\n",
    "A `set` removes all dublicate elements. We want a dictionary we can use for all songs therefore we must create a set from all songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2257a292-d9b6-4eb6-8716-c43a8b950691",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set of all chars\n",
    "chars = set(' '.join(songs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a5658b4-dec4-407f-9388-cfaac3e94fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionaries, linking a integer to a symbol\n",
    "int2char_dict = dict(enumerate(chars))\n",
    "char2int_dict = { int2char_dict[k]:k for k in int2char_dict}\n",
    "#print(int2char_dict[6])\n",
    "#print(char2int_dict['E'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005be3d9-90ec-44b7-b323-d557b0865575",
   "metadata": {},
   "source": [
    "Now turn the sequences into integers. We then want to use `OneHot` of pytorch to encode the sequences as Propability Mass Vectors.\n",
    "\n",
    "The resulting tensor `sequences_OH` does now have the shape (seq_n, seq_len, len(chars)) as each character is represented by a len(chars)-long base vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c831e032-0e97-40c8-9965-ba40277c1360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn the sequences into integers by dictionary\n",
    "#sequences_int = torch.tensor([[char2int_dict[char] for char in seq] for seq in sequences])\n",
    "#print(sequences_int.dtype)\n",
    "\n",
    "#one-hot encoding\n",
    "#sequences_OH = F.one_hot(sequences_int)\n",
    "#print(sequences_OH[0,0])\n",
    "#print(sequences_int[0,0])\n",
    "#print(sequences[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d6b84e-6077-43af-ad04-80aff57479bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8444d99e-6655-484e-a01b-76f485dde3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequences_int[0]\n",
    "#print(''.join([int2char[ch] for ch in sequences_int[0]]))\n",
    "\n",
    "def OneHotSequence2String(seq):\n",
    "    seq = seq.numpy()\n",
    "    seq = np.argmax(seq, axis=1)\n",
    "    return ''.join([int2char_dict[ch] for ch in seq])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273aa925-8f7e-4768-9370-33ab020d31ab",
   "metadata": {},
   "source": [
    "Now define a custom Dataset-Class and DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3eeee0e4-184f-4a15-8b23-0ce928b06b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LyricsDataset(Dataset):\n",
    "    def __init__(self, songs, seq_len, dict_len, int2char, char2int): #constructor\n",
    "        \n",
    "        self.seq_len = seq_len\n",
    "        self.dict_len = dict_len\n",
    "        self.int2char = int2char\n",
    "        self.char2int = char2int\n",
    "        \n",
    "        \n",
    "        self.songs = songs\n",
    "        self.sequences_raw = songs2contSequences(self.songs, self.seq_len)\n",
    "        #turn the sequences into integers by dictionary\n",
    "        self.sequences_int = torch.tensor([[self.char2int[char] for char in seq] for seq in self.sequences_raw])\n",
    "        #one-hot encoding\n",
    "        self.sequences = F.one_hot(self.sequences_int).to(float)\n",
    "        \n",
    "        #target: forward(sequences[i]) predicts sequences_target[i]=sequences[i+1]\n",
    "        #take the raw sequence and advance one element\n",
    "        self.sequences_target_raw = np.roll(self.sequences_raw,-1)\n",
    "        self.sequencess_target_int = torch.tensor([[self.char2int[char] for char in seq] for seq in self.sequences_target_raw])\n",
    "        self.sequences_target = F.one_hot(self.sequencess_target_int).to(float)\n",
    "\n",
    "\n",
    "    def __len__(self): \n",
    "        return self.sequences.shape[0] #return the number of sequences\n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "        return self.sequences[idx], self.sequences_target[idx] #return the sequences and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19292843-1052-4ea3-afad-6a93bb9213da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LyricsDataset(songs,SEQUENCE_LEN, len(chars), int2char_dict, char2int_dict)\n",
    "dataloader = DataLoader(dataset, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e015a2f-d655-4128-ad63-146f52fb8e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 100, 77])\n",
      "Lost in my reaction\n",
      "\n",
      "Dancing like a Parapara star in Japan\n",
      "\n",
      "My name is like a thunder\n",
      "\n",
      "Baby, you can\n",
      "----------\n",
      "ost in my reaction\n",
      "\n",
      "Dancing like a Parapara star in Japan\n",
      "\n",
      "My name is like a thunder\n",
      "\n",
      "Baby, you can \n"
     ]
    }
   ],
   "source": [
    "for seq, tar in dataloader:\n",
    "    print(tar.shape)\n",
    "    print(OneHotSequence2String(seq[0]))\n",
    "    print('----------')\n",
    "    print(OneHotSequence2String(tar[0]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2c89ba-d71d-4eb2-8d2b-e6165f0281a3",
   "metadata": {},
   "source": [
    "# Define a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "493708e6-576e-44b7-b753-2b7b28f38940",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMNetwork(torch.nn.Module):\n",
    "    #seq_length: length of seqeunce: 100\n",
    "    # char_dim: length of hot ones base vectors/length of dictionary\n",
    "    #hidden layer dim\n",
    "    def __init__(self, sequence_dim, char_dim, hidden_dim, n_layers, dropout_prob):\n",
    "        super().__init__()\n",
    "        self.sequence_dim = sequence_dim\n",
    "        self.char_dim = char_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_prob = dropout_prob\n",
    "\n",
    "        #lstm\n",
    "        self.lstm = torch.nn.LSTM(input_size=self.char_dim, hidden_size=self.hidden_dim,\n",
    "                                 num_layers=self.n_layers, batch_first=True,\n",
    "                                 dropout=self.dropout_prob)\n",
    "        \n",
    "\n",
    "        # The linear layer that maps from hidden state space to char-propability space\n",
    "        self.lin = torch.nn.Linear(self.hidden_dim, self.char_dim)\n",
    "        \n",
    "        #init the hidden layer, weights and bias of lstm and lin\n",
    "\n",
    "    def forward(self, x_n, hc_prev):\n",
    "        #print(f'{self.lstm}')\n",
    "        y_n, hc = self.lstm(x_n, hc_prev)\n",
    "        \n",
    "        #stack up the 2 lstm cells, send output of fisrt into second\n",
    "        y_n = y_n.contiguous().view(y_n.size()[0]*y_n.size()[1], self.hidden_dim)\n",
    "        \n",
    "        ## Put y_n through the output\n",
    "        y_n = self.lin(y_n)\n",
    "        \n",
    "        return y_n, hc\n",
    "    \n",
    "    def forwardTEST(self, x_n, hc_prev):\n",
    "        #print(f'{self.lstm}')\n",
    "        y_n, hc = self.lstm(x_n, hc_prev)\n",
    "        \n",
    "        #print(y_n.size())\n",
    "        y_test = y_n\n",
    "        #stack up the 2 lstm cells, send output of fisrt into second \n",
    "        y_n = y_n.contiguous().view(y_n.size()[0]*y_n.size()[1], self.hidden_dim)\n",
    "        \n",
    "        ## Put y_n through the output\n",
    "        y_n = self.lin(y_n)\n",
    "        \n",
    "        return y_test, y_n, hc\n",
    "    \n",
    "    \n",
    "    #this is called after training to generate a new character based on the on before\n",
    "    #incase this isn't the first char to be generated: pay attention to the hidden state,\n",
    "    #carrying the information of prev states\n",
    "    def predict(self, char, h, char2int, int2char):\n",
    "        #convert and reshape\n",
    "        char_int = char2int[char]\n",
    "        char_int = torch.reshape(torch.tensor(char_int), (1,-1))\n",
    "        char_oh = F.one_hot(char_int, num_classes=self.char_dim).to(float)\n",
    "        #init hidden layers\n",
    "        if (h is None):\n",
    "            h = self.init_hidden(1)\n",
    "        h = tuple([hc.data for hc in h])\n",
    "        \n",
    "        #get the output from the model\n",
    "        prediction, h = net.forward(char_oh, h)\n",
    "        \n",
    "        #----------------------------------\n",
    "        #apply softmax to get a normed propability distribution\n",
    "        softm = torch.nn.Softmax(dim=1)\n",
    "        prediction = softm(prediction) #torch.squeeze(prediction)\n",
    "        \n",
    "        prediction_oh = prediction\n",
    "        \n",
    "        #----------------------------------\n",
    "\n",
    "        #convert into numpy array\n",
    "        prediction_oh = prediction_oh.detach().numpy()\n",
    "        \n",
    "        #get the corresponding character\n",
    "        \n",
    "        prediction_selection = np.argsort(prediction_oh)[-1:]\n",
    "        prediction_selection = prediction_selection.squeeze()\n",
    "        prediction_int = np.random.choice(prediction_selection)\n",
    "\n",
    "        prediction_char = int2char[prediction_int]\n",
    "        \n",
    "        return prediction_char, h\n",
    "        \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # Create two new tensors with sizes (n_layers, n_seqs, hidden_dim)\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        return (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6f24dfa-bdcb-4a15-98e0-125a3d70a24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------testing\n",
    "\n",
    "#prep data\n",
    "dataset = LyricsDataset(songs, seq_len=SEQUENCE_LEN, dict_len=len(chars), int2char=int2char_dict, char2int=char2int_dict)\n",
    "data = DataLoader(dataset, batch_size=5, drop_last=True)\n",
    "\n",
    "net_test2 = LSTMNetwork(sequence_dim=dataset.seq_len, char_dim=dataset.dict_len, hidden_dim=128, n_layers=2, dropout_prob=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac5b01d3-01d3-4b81-a369-e95cedd76a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(data))[0] #x\n",
    "net_test2 = net_test2.double()\n",
    "h = net_test2.init_hidden(5)\n",
    "y_test, out , (h,_) = net_test2.forwardTEST(x, h)\n",
    "\n",
    "ytt = y_test.contiguous().view(y_test.size()[0]*y_test.size()[1], net_test2.hidden_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7a171d-e8e8-4d89-a5b7-ad8fb132796b",
   "metadata": {},
   "source": [
    "# Training process\n",
    "\n",
    "1. Beginn by defining:\n",
    "- `opt` The optimization algorithm (Gradient decent).\n",
    "- `loss_function` Evaluate the accuracy of the current state with the Cross Entropy Function.\n",
    "2. Next, set the model into training mode, this is only relevant for the Dropout Layer.\n",
    "3. We will loop over the whole data several times with the `epochs` loop.\n",
    "4. For every epoch the hidden layer needs to be reset.\n",
    "5. Now we loop over the batches of our dataset. We have a `target` batch with which we will later compare the processed `input`.\n",
    "6. Reset the Gradient and reintroduce the hidden state, this prevents the backwards propagation from going beyond the current state.\n",
    "7. Now finally, calculate the predictions `output`. This also returns the hidden state `h`.\n",
    "8. Perform the backwards propagation:\n",
    "- Calculate the loss.\n",
    "- Call `backward()`.\n",
    "- `clip_grad_norm_` prevents the parameters from exploding.\n",
    "- update the parameters.\n",
    "9. print the training status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d7bf37d-f949-4147-8b4e-88fcb68015d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(net, data, sequence_dim, dict_len, batch_size,  epochs=10, lr=0.01):\n",
    "    \n",
    "    net = net.double()\n",
    "    \n",
    "    # optimizer\n",
    "    opt = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    # loss\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    #need to set the mode\n",
    "    net.train()\n",
    "        \n",
    "    losses = []\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        lo = 0\n",
    "        counter = 0\n",
    "\n",
    "        #initialize hidden state\n",
    "        h = net.init_hidden(batch_size)\n",
    "        \n",
    "        for inputs, targets in data:\n",
    "            counter+= 1\n",
    "            \n",
    "            #reset the gradients\n",
    "            net.zero_grad()\n",
    "            #reentroduce the hidden state\n",
    "            h = tuple([hc.data for hc in h])\n",
    "            #get the output from the model\n",
    "            outputs, h = net.forward(inputs, h)\n",
    "            \n",
    "            #calculate the loss and perform backprop\n",
    "            loss = loss_function(outputs, targets.contiguous().view(batch_size*sequence_dim,-1))\n",
    "            lo += loss\n",
    "            #back-propagate error\n",
    "            loss.backward()\n",
    "            #helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "            torch.nn.utils.clip_grad_norm_(net.parameters(), 5)\n",
    "            # update weigths\n",
    "            opt.step()\n",
    "            \n",
    "            \n",
    "            if counter % 50 == 0:\n",
    "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                    \"Step: {}...\".format(counter))\n",
    "        losses.append(lo)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b5f8dc-f7c9-4b53-87f2-a2094e2b98be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f19617-b6fd-49e4-856c-139f1c9640d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2bb9b129-ce56-4ebe-a759-a11bf5d8f209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prep data\n",
    "batch_size = 20\n",
    "dataset = LyricsDataset(songs, seq_len=SEQUENCE_LEN, dict_len=len(chars), int2char=int2char_dict, char2int=char2int_dict)\n",
    "data = DataLoader(dataset, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14416137-2fc9-40b0-b42e-02e354dddc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10... Step: 50...\n",
      "Epoch: 1/10... Step: 100...\n",
      "Epoch: 1/10... Step: 150...\n",
      "Epoch: 1/10... Step: 200...\n",
      "Epoch: 1/10... Step: 250...\n",
      "Epoch: 1/10... Step: 300...\n",
      "Epoch: 2/10... Step: 50...\n",
      "Epoch: 2/10... Step: 100...\n",
      "Epoch: 2/10... Step: 150...\n",
      "Epoch: 2/10... Step: 200...\n",
      "Epoch: 2/10... Step: 250...\n",
      "Epoch: 2/10... Step: 300...\n",
      "Epoch: 3/10... Step: 50...\n",
      "Epoch: 3/10... Step: 100...\n",
      "Epoch: 3/10... Step: 150...\n",
      "Epoch: 3/10... Step: 200...\n",
      "Epoch: 3/10... Step: 250...\n",
      "Epoch: 3/10... Step: 300...\n",
      "Epoch: 4/10... Step: 50...\n",
      "Epoch: 4/10... Step: 100...\n",
      "Epoch: 4/10... Step: 150...\n",
      "Epoch: 4/10... Step: 200...\n",
      "Epoch: 4/10... Step: 250...\n",
      "Epoch: 4/10... Step: 300...\n",
      "Epoch: 5/10... Step: 50...\n",
      "Epoch: 5/10... Step: 100...\n",
      "Epoch: 5/10... Step: 150...\n",
      "Epoch: 5/10... Step: 200...\n",
      "Epoch: 5/10... Step: 250...\n",
      "Epoch: 5/10... Step: 300...\n",
      "Epoch: 6/10... Step: 50...\n",
      "Epoch: 6/10... Step: 100...\n",
      "Epoch: 6/10... Step: 150...\n",
      "Epoch: 6/10... Step: 200...\n",
      "Epoch: 6/10... Step: 250...\n",
      "Epoch: 6/10... Step: 300...\n",
      "Epoch: 7/10... Step: 50...\n",
      "Epoch: 7/10... Step: 100...\n",
      "Epoch: 7/10... Step: 150...\n",
      "Epoch: 7/10... Step: 200...\n",
      "Epoch: 7/10... Step: 250...\n",
      "Epoch: 7/10... Step: 300...\n",
      "Epoch: 8/10... Step: 50...\n",
      "Epoch: 8/10... Step: 100...\n",
      "Epoch: 8/10... Step: 150...\n",
      "Epoch: 8/10... Step: 200...\n",
      "Epoch: 8/10... Step: 250...\n",
      "Epoch: 8/10... Step: 300...\n",
      "Epoch: 9/10... Step: 50...\n",
      "Epoch: 9/10... Step: 100...\n",
      "Epoch: 9/10... Step: 150...\n",
      "Epoch: 9/10... Step: 200...\n",
      "Epoch: 9/10... Step: 250...\n",
      "Epoch: 9/10... Step: 300...\n",
      "Epoch: 10/10... Step: 50...\n",
      "Epoch: 10/10... Step: 100...\n",
      "Epoch: 10/10... Step: 150...\n",
      "Epoch: 10/10... Step: 200...\n",
      "Epoch: 10/10... Step: 250...\n",
      "Epoch: 10/10... Step: 300...\n"
     ]
    }
   ],
   "source": [
    "# Initialize and print the network\n",
    "net = LSTMNetwork(sequence_dim=dataset.seq_len, char_dim=dataset.dict_len, hidden_dim=128, n_layers=2, dropout_prob=0.5)\n",
    "\n",
    "#training\n",
    "loss = training(net, data, sequence_dim=dataset.seq_len, dict_len=dataset.dict_len, batch_size=batch_size, epochs=10, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c04518fd-5479-4bd6-a60f-e22c3f883caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x26f31b8e140>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array([el.detach().numpy() for el in loss]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "54ef8480-a560-467b-b838-120fc4fd2634",
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = LSTMNetwork(sequence_dim=dataset.seq_len, char_dim=dataset.dict_len, hidden_dim=128, n_layers=2, dropout_prob=0.5)\n",
    "net2.lstm = net.lstm\n",
    "net2.lin = net.lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "93caee95-39c9-4f23-a7c9-2d91afc5bef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS3L!G:5EF\"re(jLcfTN83bV2iJB\n",
      "moY)GaggGQ31bb2n(tW(\n"
     ]
    }
   ],
   "source": [
    "let = 'K'\n",
    "h_m = None\n",
    "\n",
    "sent = [let]\n",
    "for k in range(50):\n",
    "    let, h_m = net2.predict(let, h_m, char2int_dict, int2char_dict)\n",
    "    sent.append(let)\n",
    "    \n",
    "print(''.join(sent))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0fd808a9-2f6e-4cfa-8d37-71b2d87717f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['K',\n",
       " 'd',\n",
       " 'p',\n",
       " \"'\",\n",
       " 'w',\n",
       " 'K',\n",
       " '7',\n",
       " 'K',\n",
       " 'N',\n",
       " 'd',\n",
       " 'X',\n",
       " 'r',\n",
       " 't',\n",
       " 'o',\n",
       " '(',\n",
       " 'U',\n",
       " '-',\n",
       " 'A',\n",
       " 'm',\n",
       " 'k',\n",
       " 'w']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0b19f0-fd72-48b7-9944-0ee9368e35b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c159e7c3-e41e-4803-beb6-42d2eda26803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fd8c88-d0d5-46e2-afcd-f3c24b7a3533",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
