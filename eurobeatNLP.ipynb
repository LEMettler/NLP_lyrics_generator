{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8daf4d7-c9a9-4325-bc9d-60b5028ed40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63b501b7-14a7-4aa4-adbc-40cd12e3d651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants\n",
    "SEQUENCE_LEN = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8834c22a-6ac0-4f20-8c42-9473761a499b",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "- die dictionaries sollen funktional, unabha√§ngig vond er klasse sein, also werden die songs als solche ebreits auserhalb genereirt, dann einfach songs drausen generieren, dict anlegen, dann klasse schreiben die songs bekommt\n",
    "\n",
    "- https://github.com/LeanManager/NLP-PyTorch/blob/master/Character-Level%20LSTM%20with%20PyTorch.ipynb\n",
    "- https://www.analyticsvidhya.com/blog/2020/08/build-a-natural-language-generation-nlg-system-using-pytorch/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fc8bd7-7936-413c-928d-a1bcd2e430d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load and prepare Data\n",
    "\n",
    "Lets begin by importing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ab4ea04-779b-43f1-9c68-bf8ab7821eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'eurobeat_lyrics.csv'\n",
    "\n",
    "songs  = np.array(open(file,'r').read().split(';'))\n",
    "songs = songs[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7bfda95-d96c-4036-a21c-20ebc9ec040d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to call in dataset class\n",
    "def getSongs(filepath):\n",
    "    songs  = np.array(open(file,'r').read().split(';'))\n",
    "    return songs[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae378ca-d926-4a6a-b529-e5bca65c542b",
   "metadata": {},
   "source": [
    "The songs have different lengths. We want to split the songs in sequences of characters, all the same length. We also want the sequences to overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e67ac6f-7490-4d86-b048-999c6139b760",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a whole song and return an array (n, seq_len) of n seqeunces of length seq_len, which are the characters of the song\n",
    "#each sequence has teh same length\n",
    "def song2sequences(song, seq_len):\n",
    "    song_len = len(song)\n",
    "    n_seq = 2*(song_len//seq_len)\n",
    "    seq = np.empty((n_seq, seq_len), dtype=str)\n",
    "    \n",
    "    song = np.array([ch for ch in song])\n",
    "    for i in range(n_seq-1):\n",
    "        seq[i] = song[int(i*(seq_len/2)) : int(seq_len + i*seq_len/2)]\n",
    "    seq[n_seq-1] = song[-(seq_len):]\n",
    "    \n",
    "    return seq\n",
    "\n",
    "#lets create all the sequences for all our songs and concatenate them in one array\n",
    "#so proud i wrote this line myself\n",
    "def songs2sequences(songs, seq_len=SEQUENCE_LEN):\n",
    "    return np.concatenate(([song2sequences(song, seq_len) for song in songs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a93e7933-8e2c-46fa-b089-7836df31fb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequences = songs2sequences(songs,SEQUENCE_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f66af8-381a-444c-915f-d08c97906550",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "Create a dictionary to link letters to numbers.\n",
    "\n",
    "A `set` removes all dublicate elements. We want a dictionary we can use for all songs therefore we must create a set from all songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2257a292-d9b6-4eb6-8716-c43a8b950691",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set of all chars\n",
    "chars = set(' '.join(songs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a5658b4-dec4-407f-9388-cfaac3e94fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionaries, linking a integer to a symbol\n",
    "int2char_dict = dict(enumerate(chars))\n",
    "char2int_dict = { int2char[k]:k for k in int2char}\n",
    "#print(int2char_dict[6])\n",
    "#print(char2int_dict['E'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005be3d9-90ec-44b7-b323-d557b0865575",
   "metadata": {},
   "source": [
    "Now turn the sequences into integers. We then want to use `OneHot` of pytorch to encode the sequences as Propability Mass Vectors.\n",
    "\n",
    "The resulting tensor `sequences_OH` does now have the shape (seq_n, seq_len, len(chars)) as each character is represented by a len(chars)-long base vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c831e032-0e97-40c8-9965-ba40277c1360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn the sequences into integers by dictionary\n",
    "#sequences_int = torch.tensor([[char2int_dict[char] for char in seq] for seq in sequences])\n",
    "#print(sequences_int.dtype)\n",
    "\n",
    "#one-hot encoding\n",
    "#sequences_OH = F.one_hot(sequences_int)\n",
    "#print(sequences_OH[0,0])\n",
    "#print(sequences_int[0,0])\n",
    "#print(sequences[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d6b84e-6077-43af-ad04-80aff57479bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8444d99e-6655-484e-a01b-76f485dde3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequences_int[0]\n",
    "#print(''.join([int2char[ch] for ch in sequences_int[0]]))\n",
    "\n",
    "def OneHotSequence2String(seq):\n",
    "    seq = seq.numpy()\n",
    "    seq = np.argmax(seq, axis=1)\n",
    "    return ''.join([int2char_dict[ch] for ch in seq])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273aa925-8f7e-4768-9370-33ab020d31ab",
   "metadata": {},
   "source": [
    "Now define a custom Dataset-Class and DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3eeee0e4-184f-4a15-8b23-0ce928b06b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LyricsDataset(Dataset):\n",
    "    def __init__(self, songs, seq_len, dict_len, int2char, char2int): #constructor\n",
    "        \n",
    "        self.seq_len = seq_len\n",
    "        self.dict_len = dict_len\n",
    "        self.int2char = int2char\n",
    "        self.char2int = char2int\n",
    "        \n",
    "        \n",
    "        self.songs = songs\n",
    "        self.sequences_raw = songs2sequences(self.songs, self.seq_len)\n",
    "        #turn the sequences into integers by dictionary\n",
    "        self.sequences_int = torch.tensor([[self.char2int[char] for char in seq] for seq in self.sequences_raw])\n",
    "        #one-hot encoding\n",
    "        self.sequences = F.one_hot(self.sequences_int).to(float)\n",
    "        \n",
    "        #target: forward(sequences[i]) predicts sequences_target[i]=sequences[i+1]\n",
    "        #take the raw sequence and advance one element\n",
    "        self.sequences_target_raw = np.roll(self.sequences_raw,-1)\n",
    "        self.sequencess_target_int = torch.tensor([[self.char2int[char] for char in seq] for seq in self.sequences_target_raw])\n",
    "        self.sequences_target = F.one_hot(self.sequencess_target_int).to(float)\n",
    "\n",
    "\n",
    "    def __len__(self): \n",
    "        return self.sequences.shape[0] #return the number of sequences\n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "        return self.sequences[idx], self.sequences_target[idx] #return the sequences and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "19292843-1052-4ea3-afad-6a93bb9213da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LyricsDataset(songs,SEQUENCE_LEN, len(chars), int2char_dict, char2int_dict)\n",
    "dataloader = DataLoader(dataset, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4e015a2f-d655-4128-ad63-146f52fb8e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 100, 67])\n",
      "Lost in my reaction\n",
      "\n",
      "Dancing like a Parapara star in Japan\n",
      "\n",
      "My name is like a thunder\n",
      "\n",
      "Baby, you can\n",
      "----------\n",
      "ost in my reaction\n",
      "\n",
      "Dancing like a Parapara star in Japan\n",
      "\n",
      "My name is like a thunder\n",
      "\n",
      "Baby, you cani\n"
     ]
    }
   ],
   "source": [
    "for seq, tar in dataloader:\n",
    "    print(tar.shape)\n",
    "    print(OneHotSequence2String(seq[0]))\n",
    "    print('----------')\n",
    "    print(OneHotSequence2String(tar[0]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2c89ba-d71d-4eb2-8d2b-e6165f0281a3",
   "metadata": {},
   "source": [
    "# Define a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "493708e6-576e-44b7-b753-2b7b28f38940",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMNetwork(torch.nn.Module):\n",
    "    #seq_length: length of seqeunce: 100\n",
    "    # char_dim: length of hot ones base vectors/length of dictionary\n",
    "    #hidden layer dim\n",
    "    def __init__(self, sequence_dim, char_dim, hidden_dim, n_layers, dropout_prob):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.sequence_dim = sequence_dim\n",
    "        self.char_dim = char_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_prob = dropout_prob\n",
    "\n",
    "        #lstm\n",
    "        self.lstm = torch.nn.LSTM(input_size=self.char_dim, hidden_size=self.hidden_dim,\n",
    "                                 num_layers=self.n_layers, batch_first=True,\n",
    "                                 dropout=self.dropout_prob)\n",
    "        \n",
    "\n",
    "        # The linear layer that maps from hidden state space to char-propability space\n",
    "        self.lin = torch.nn.Linear(self.hidden_dim, self.char_dim)\n",
    "        \n",
    "        #init the hidden layer, weights and bias of lstm and lin\n",
    "\n",
    "    def forward(self, x_n, hc_prev):\n",
    "        \n",
    "        y_n, (h_n, c_n) = self.lstm(x_n, hc_prev)\n",
    "        \n",
    "        #stack up the 2 lstm cells, send output of fisrt into second \n",
    "        y_n = y_n.view(y_n.size()[0]*y_n.size()[1], self.hidden_dim)\n",
    "        \n",
    "        ## Put y_n through the output\n",
    "        y_n = self.fc(y_n)\n",
    "        \n",
    "        return y_n, (h_n, c_n)\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # Create two new tensors with sizes (n_layers, n_seqs, hidden_dim)\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        return (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7a171d-e8e8-4d89-a5b7-ad8fb132796b",
   "metadata": {},
   "source": [
    "# Training process\n",
    "\n",
    "1. Beginn by defining:\n",
    "- `opt` The optimization algorithm (Gradient decent).\n",
    "- `loss_function` Evaluate the accuracy of the current state with the Cross Entropy Function.\n",
    "2. Next, set the model into training mode, this is only relevant for the Dropout Layer.\n",
    "3. We will loop over the whole data several times with the `epochs` loop.\n",
    "4. For every epoch the hidden layer needs to be reset.\n",
    "5. Now we loop over the batches of our dataset. We have a `target` batch with which we will later compare the processed `input`.\n",
    "6. Reset the Gradient and reintroduce the hidden state, this prevents the backwards propagation from going beyond the current state.\n",
    "7. Now finally, calculate the predictions `output`. This also returns the hidden state `h`.\n",
    "8. Perform the backwards propagation:\n",
    "- Calculate the loss.\n",
    "- Call `backward()`.\n",
    "- `clip_grad_norm_` prevents the parameters from exploding.\n",
    "- update the parameters.\n",
    "9. print the training status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6d7bf37d-f949-4147-8b4e-88fcb68015d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(net, data, sequence_dim, dict_len, batch_size,  epochs=10, lr=0.01):\n",
    "    # optimizer\n",
    "    opt = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    # loss\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    #need to set the mode\n",
    "    net.train()\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    for e in range(epochs):\n",
    "\n",
    "        #initialize hidden state\n",
    "        h = net.init_hidden(batch_size)\n",
    "        \n",
    "        for inputs, targets in data:\n",
    "            counter+= 1\n",
    "            \n",
    "            #reset the gradients\n",
    "            net.zero_grad()\n",
    "            #reentroduce the hidden state\n",
    "            h = tuple([each.data for each in h])\n",
    "       \n",
    "            #get the output from the model\n",
    "            outputs, h = net.forward(inputs, h)\n",
    "            \n",
    "            #TODO is softmax included in cross entropy? otherwise here\n",
    "            \n",
    "            #calculate the loss and perform backprop\n",
    "            loss = loss_function(outputs, targets)\n",
    "            #back-propagate error\n",
    "            loss.backward()\n",
    "            #helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "            torch.nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "            # update weigths\n",
    "            opt.step()            \n",
    "            \n",
    "            if counter % print_every == 0:\n",
    "            \n",
    "              print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                    \"Step: {}...\".format(counter))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
